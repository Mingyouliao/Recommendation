{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mpltw\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#plt.style.use('seaborn')\n",
    "from Sales_Pipeline import pipeline, user_item_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_1 = pd.read_excel('../iCheers_data_new/iCheers銷售記錄(2021).xlsx')\n",
    "sales_2 = pd.read_excel('../iCheers_data_new/iCheers銷售記錄(2022).xlsx')\n",
    "item = pd.read_excel('../iCheers_data_new/iCheers酒款資料.xlsx')\n",
    "grape = pd.read_excel('../iCheers_data_new/iCheers品種.xlsx')\n",
    "users = pd.read_excel('../iCheers_data_new/iCheers客戶資料.xlsx')\n",
    "\n",
    "#資料預處理\n",
    "grape = grape.groupby('上架編號').agg({'品種': lambda x: '+'.join(list(x))})\n",
    "sales_1 = pipeline(sales_1, item, grape)\n",
    "sales_2 = pipeline(sales_2, item, grape)\n",
    "sales = pd.concat([sales_1, sales_2], axis=0)\n",
    "area = '細區' #目前只能用細區\n",
    "criteria = '銷貨數量' #只會影響相似度的計算\n",
    "UI_mat = user_item_matrix(sales, area=area, criteria=criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>細區</th>\n",
       "      <th>以色列戈蘭高地加利利</th>\n",
       "      <th>以色列戈蘭高地加利利白</th>\n",
       "      <th>以色列戈蘭高地加利利紅</th>\n",
       "      <th>匈牙利Eger 白</th>\n",
       "      <th>匈牙利Somlo 白</th>\n",
       "      <th>匈牙利Villany 白</th>\n",
       "      <th>匈牙利Villany 粉紅</th>\n",
       "      <th>匈牙利Villany 紅</th>\n",
       "      <th>匈牙利托凱 琥珀色</th>\n",
       "      <th>匈牙利托凱 白</th>\n",
       "      <th>...</th>\n",
       "      <th>阿根廷門多薩San Carlos紅</th>\n",
       "      <th>阿根廷門多薩Santa Rosa紅</th>\n",
       "      <th>阿根廷門多薩Tunuyan紅</th>\n",
       "      <th>阿根廷門多薩Tupungato - Valle de Tupungato 白</th>\n",
       "      <th>阿根廷門多薩烏格河谷白</th>\n",
       "      <th>阿根廷門多薩烏格河谷紅</th>\n",
       "      <th>阿根廷黑河 紅</th>\n",
       "      <th>黎巴嫩  白</th>\n",
       "      <th>黎巴嫩  粉紅</th>\n",
       "      <th>黎巴嫩  紅</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>客戶代碼</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000354fe836b0f0d385ab4c07ff0ac17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0007484d651c9a8127ac33a505f37fd1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000b865d608f7c0137c72cf8f00e3559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001734fefec772f1814d89d4141460c7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00178e471d27295a13f0f961325e28c4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff2f7701c2616bb5d66a0feb6336fbf</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff6098244d0bbcd94e1888fd4648a76</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff7caa578aa7e7134ccf687f7c2d3c2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc530c3ecffc53a0c018fab14e5475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffccd0debf95257c380505a6491a2b5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10403 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "細區                                以色列戈蘭高地加利利   以色列戈蘭高地加利利白  以色列戈蘭高地加利利紅  \\\n",
       "客戶代碼                                                                      \n",
       "000354fe836b0f0d385ab4c07ff0ac17          0.0          0.0          0.0   \n",
       "0007484d651c9a8127ac33a505f37fd1          0.0          0.0          0.0   \n",
       "000b865d608f7c0137c72cf8f00e3559          0.0          0.0          0.0   \n",
       "001734fefec772f1814d89d4141460c7          0.0          0.0          0.0   \n",
       "00178e471d27295a13f0f961325e28c4          0.0          0.0          0.0   \n",
       "...                                       ...          ...          ...   \n",
       "fff2f7701c2616bb5d66a0feb6336fbf          0.0          0.0          0.0   \n",
       "fff6098244d0bbcd94e1888fd4648a76          0.0          0.0          0.0   \n",
       "fff7caa578aa7e7134ccf687f7c2d3c2          0.0          0.0          0.0   \n",
       "fffc530c3ecffc53a0c018fab14e5475          0.0          0.0          0.0   \n",
       "fffccd0debf95257c380505a6491a2b5          0.0          0.0          0.0   \n",
       "\n",
       "細區                                匈牙利Eger 白  匈牙利Somlo 白  匈牙利Villany 白  \\\n",
       "客戶代碼                                                                    \n",
       "000354fe836b0f0d385ab4c07ff0ac17        0.0         0.0           0.0   \n",
       "0007484d651c9a8127ac33a505f37fd1        0.0         0.0           0.0   \n",
       "000b865d608f7c0137c72cf8f00e3559        0.0         0.0           0.0   \n",
       "001734fefec772f1814d89d4141460c7        0.0         0.0           0.0   \n",
       "00178e471d27295a13f0f961325e28c4        0.0         0.0           0.0   \n",
       "...                                     ...         ...           ...   \n",
       "fff2f7701c2616bb5d66a0feb6336fbf        0.0         0.0           0.0   \n",
       "fff6098244d0bbcd94e1888fd4648a76        0.0         0.0           0.0   \n",
       "fff7caa578aa7e7134ccf687f7c2d3c2        0.0         0.0           0.0   \n",
       "fffc530c3ecffc53a0c018fab14e5475        0.0         0.0           0.0   \n",
       "fffccd0debf95257c380505a6491a2b5        0.0         0.0           0.0   \n",
       "\n",
       "細區                                匈牙利Villany 粉紅  匈牙利Villany 紅  匈牙利托凱 琥珀色  \\\n",
       "客戶代碼                                                                       \n",
       "000354fe836b0f0d385ab4c07ff0ac17            0.0           0.0        0.0   \n",
       "0007484d651c9a8127ac33a505f37fd1            0.0           0.0        0.0   \n",
       "000b865d608f7c0137c72cf8f00e3559            0.0           0.0        0.0   \n",
       "001734fefec772f1814d89d4141460c7            0.0           0.0        0.0   \n",
       "00178e471d27295a13f0f961325e28c4            0.0           0.0        0.0   \n",
       "...                                         ...           ...        ...   \n",
       "fff2f7701c2616bb5d66a0feb6336fbf            0.0           0.0        0.0   \n",
       "fff6098244d0bbcd94e1888fd4648a76            0.0           0.0        0.0   \n",
       "fff7caa578aa7e7134ccf687f7c2d3c2            0.0           0.0        0.0   \n",
       "fffc530c3ecffc53a0c018fab14e5475            0.0           0.0        0.0   \n",
       "fffccd0debf95257c380505a6491a2b5            0.0           0.0        0.0   \n",
       "\n",
       "細區                                匈牙利托凱 白  ...  阿根廷門多薩San Carlos紅  \\\n",
       "客戶代碼                                       ...                      \n",
       "000354fe836b0f0d385ab4c07ff0ac17      0.0  ...                0.0   \n",
       "0007484d651c9a8127ac33a505f37fd1      0.0  ...                0.0   \n",
       "000b865d608f7c0137c72cf8f00e3559      0.0  ...                0.0   \n",
       "001734fefec772f1814d89d4141460c7      0.0  ...                0.0   \n",
       "00178e471d27295a13f0f961325e28c4      0.0  ...                0.0   \n",
       "...                                   ...  ...                ...   \n",
       "fff2f7701c2616bb5d66a0feb6336fbf      0.0  ...                0.0   \n",
       "fff6098244d0bbcd94e1888fd4648a76      0.0  ...                0.0   \n",
       "fff7caa578aa7e7134ccf687f7c2d3c2      0.0  ...                0.0   \n",
       "fffc530c3ecffc53a0c018fab14e5475      0.0  ...                0.0   \n",
       "fffccd0debf95257c380505a6491a2b5      0.0  ...                0.0   \n",
       "\n",
       "細區                                阿根廷門多薩Santa Rosa紅  阿根廷門多薩Tunuyan紅  \\\n",
       "客戶代碼                                                                  \n",
       "000354fe836b0f0d385ab4c07ff0ac17                0.0             0.0   \n",
       "0007484d651c9a8127ac33a505f37fd1                0.0             0.0   \n",
       "000b865d608f7c0137c72cf8f00e3559                0.0             0.0   \n",
       "001734fefec772f1814d89d4141460c7                0.0             0.0   \n",
       "00178e471d27295a13f0f961325e28c4                0.0             0.0   \n",
       "...                                             ...             ...   \n",
       "fff2f7701c2616bb5d66a0feb6336fbf                0.0             0.0   \n",
       "fff6098244d0bbcd94e1888fd4648a76                0.0             0.0   \n",
       "fff7caa578aa7e7134ccf687f7c2d3c2                0.0             0.0   \n",
       "fffc530c3ecffc53a0c018fab14e5475                0.0             0.0   \n",
       "fffccd0debf95257c380505a6491a2b5                0.0             0.0   \n",
       "\n",
       "細區                                阿根廷門多薩Tupungato - Valle de Tupungato 白  \\\n",
       "客戶代碼                                                                       \n",
       "000354fe836b0f0d385ab4c07ff0ac17                                     0.0   \n",
       "0007484d651c9a8127ac33a505f37fd1                                     0.0   \n",
       "000b865d608f7c0137c72cf8f00e3559                                     0.0   \n",
       "001734fefec772f1814d89d4141460c7                                     0.0   \n",
       "00178e471d27295a13f0f961325e28c4                                     0.0   \n",
       "...                                                                  ...   \n",
       "fff2f7701c2616bb5d66a0feb6336fbf                                     0.0   \n",
       "fff6098244d0bbcd94e1888fd4648a76                                     0.0   \n",
       "fff7caa578aa7e7134ccf687f7c2d3c2                                     0.0   \n",
       "fffc530c3ecffc53a0c018fab14e5475                                     0.0   \n",
       "fffccd0debf95257c380505a6491a2b5                                     0.0   \n",
       "\n",
       "細區                                阿根廷門多薩烏格河谷白  阿根廷門多薩烏格河谷紅  阿根廷黑河 紅  黎巴嫩  白  \\\n",
       "客戶代碼                                                                          \n",
       "000354fe836b0f0d385ab4c07ff0ac17          0.0          0.0      0.0     0.0   \n",
       "0007484d651c9a8127ac33a505f37fd1          0.0          6.0      0.0     0.0   \n",
       "000b865d608f7c0137c72cf8f00e3559          0.0          0.0      0.0     0.0   \n",
       "001734fefec772f1814d89d4141460c7          0.0          0.0      0.0     0.0   \n",
       "00178e471d27295a13f0f961325e28c4          0.0          0.0      0.0     0.0   \n",
       "...                                       ...          ...      ...     ...   \n",
       "fff2f7701c2616bb5d66a0feb6336fbf          0.0          0.0      0.0     0.0   \n",
       "fff6098244d0bbcd94e1888fd4648a76          0.0          0.0      0.0     0.0   \n",
       "fff7caa578aa7e7134ccf687f7c2d3c2          0.0          0.0      0.0     0.0   \n",
       "fffc530c3ecffc53a0c018fab14e5475          0.0          0.0      0.0     0.0   \n",
       "fffccd0debf95257c380505a6491a2b5          2.0          2.0      0.0     0.0   \n",
       "\n",
       "細區                                黎巴嫩  粉紅  黎巴嫩  紅  \n",
       "客戶代碼                                               \n",
       "000354fe836b0f0d385ab4c07ff0ac17      0.0     0.0  \n",
       "0007484d651c9a8127ac33a505f37fd1      0.0     0.0  \n",
       "000b865d608f7c0137c72cf8f00e3559      0.0     0.0  \n",
       "001734fefec772f1814d89d4141460c7      0.0     0.0  \n",
       "00178e471d27295a13f0f961325e28c4      0.0     0.0  \n",
       "...                                   ...     ...  \n",
       "fff2f7701c2616bb5d66a0feb6336fbf      0.0     0.0  \n",
       "fff6098244d0bbcd94e1888fd4648a76      0.0     0.0  \n",
       "fff7caa578aa7e7134ccf687f7c2d3c2      0.0     0.0  \n",
       "fffc530c3ecffc53a0c018fab14e5475      0.0     0.0  \n",
       "fffccd0debf95257c380505a6491a2b5      0.0     0.0  \n",
       "\n",
       "[10403 rows x 738 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UI_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_recommendations_for_user(r_hat, user, n=10):\n",
    "    # 檢查用戶是否在DataFrame中\n",
    "    if user not in r_hat.index:\n",
    "        return None  # 或者返回一個適當的信息，比如\"用戶未找到\"\n",
    "    \n",
    "    # Get the user's rating predictions\n",
    "    user_ratings = r_hat.loc[user, :]\n",
    "    \n",
    "    # Find the indices of the top N ratings\n",
    "    top_n_indices = np.argsort(-user_ratings.values)[:n]  # 使用.values將其轉化為numpy數組\n",
    "    \n",
    "    # Get the top N ratings using the indices\n",
    "    top_n_ratings = user_ratings.iloc[top_n_indices]\n",
    "    \n",
    "    top_n_ratings = [(name, float(score)) for name, score in top_n_ratings.items()]\n",
    "    \n",
    "    return top_n_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oringinal_top_n_recommendations_for_user(r_hat, user, n=10):\n",
    "    # 檢查用戶是否在DataFrame中\n",
    "    if user not in r_hat.index:\n",
    "        return None  # 或者返回一個適當的信息，比如\"用戶未找到\"\n",
    "    \n",
    "    # Get the user's rating predictions\n",
    "    user_ratings = r_hat.loc[user, :]\n",
    "    user_ratings = user_ratings[user_ratings>0]\n",
    "    \n",
    "    # Find the indices of the top N ratings\n",
    "    top_n_indices = np.argsort(-user_ratings.values)[:n]  # 使用.values將其轉化為numpy數組\n",
    "    \n",
    "    # Get the top N ratings using the indices\n",
    "    top_n_ratings = user_ratings.iloc[top_n_indices]\n",
    "    \n",
    "    top_n_ratings = [(name, float(score)) for name, score in top_n_ratings.items()]\n",
    "    \n",
    "    return top_n_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_results(predicted_ratings, UI_mat = UI_mat):\n",
    "    # Define the user for whom we want to make predictions\n",
    "    picked_user_list = ['231228b77124b1331fbee2abfc9cf923', 'afb8a6cf419846dccdaca13bb275de65', '3b9abfef5b9dbfd31c664470dc528319',\n",
    "                     'b1f7077b077152c4f004c7180a59c2e8', 'a789b30e0893ab3d4fcdceb18e46a782', '723b7787cb8db4e2d5ff7dee3af65a49']\n",
    "                        \n",
    "    for i in picked_user_list:\n",
    "        print(i)\n",
    "        top_n_recommendations = top_n_recommendations_for_user(predicted_ratings, i, n=10)\n",
    "        print(\"這是預測的最高前10個\")\n",
    "        print(top_n_recommendations)\n",
    "        # Get the top N recommendations\n",
    "        top_n_recommendations = oringinal_top_n_recommendations_for_user(UI_mat, i, n=10)\n",
    "        print(\"這是原本最高的前10個\")\n",
    "        print(top_n_recommendations)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231228b77124b1331fbee2abfc9cf923\n",
      "這是預測的最高前10個\n",
      "[('法國布根地 白', 4.941134786265802), ('法國布根地 紅', 0.9944673727741954), ('法國布根地夏布利白', 0.9554422019623809), ('美國加州北海岸白', 0.9459003463639301), ('法國隆河谷隆河丘白', 0.37512103895876386), ('法國隆河谷 白', 0.22037892373290366), ('法國布根地夜丘白', 0.14453693478802923), ('法國布根地夏隆內丘白', 0.14153358870272556), ('法國波爾多 白', 0.13815092445870386), ('法國波爾多索甸白', 0.10254988410974758)]\n",
      "這是原本最高的前10個\n",
      "[('法國布根地 白', 5.0), ('法國布根地 紅', 1.0), ('法國布根地夏布利白', 1.0), ('美國加州北海岸白', 1.0)]\n",
      "\n",
      "\n",
      "afb8a6cf419846dccdaca13bb275de65\n",
      "這是預測的最高前10個\n",
      "[('法國布根地 紅', 10.070089560307038), ('法國隆河谷隆河丘紅', 8.14281274519138), ('法國香檳 白', 7.03819356661153), ('法國波爾多波雅克紅', 7.006703902079315), ('澳洲南澳巴羅沙谷紅', 6.91695997748518), ('法國布根地上夜丘紅', 6.143341435050479), ('美國加州 白', 6.094880298976093), ('西班牙利奧哈上利奧哈紅', 5.841532503890232), ('法國布根地夜丘紅', 5.4466727133147455), ('法國布根地 白', 5.23222281558653)]\n",
      "這是原本最高的前10個\n",
      "[('黎巴嫩  紅', 11.0), ('法國布根地 紅', 10.0), ('法國隆河谷隆河丘紅', 8.0), ('法國香檳 白', 7.0), ('澳洲南澳巴羅沙谷紅', 7.0), ('法國波爾多波雅克紅', 7.0), ('美國加州 白', 6.0), ('法國布根地上夜丘紅', 6.0), ('西班牙利奧哈上利奧哈紅', 6.0), ('法國布根地夜丘紅', 5.0)]\n",
      "\n",
      "\n",
      "3b9abfef5b9dbfd31c664470dc528319\n",
      "這是預測的最高前10個\n",
      "[('美國加州北海岸白', 0.9766823327037003), ('法國布根地夜丘紅', 0.17352722747220437), ('阿根廷門多薩烏格河谷白', 0.08382716425075908), ('法國布根地夏隆內丘白', 0.06899841031878971), ('法國香檳白丘白', 0.06774421183513185), ('美國加州中部海岸白', 0.06586301636603183), ('法國波爾多 白', 0.05437124845792573), ('法國布根地夜丘白', 0.048142266240217425), ('美國奧立岡威廉梅特谷紅', 0.047119586271487574), ('澳洲南澳 白', 0.04419471316614532)]\n",
      "這是原本最高的前10個\n",
      "[('台灣彰化二林紅', 1.0), ('法國布根地夜丘白', 1.0), ('法國羅亞爾河谷蜜思卡得粉紅', 1.0), ('紐西蘭  白', 1.0), ('美國加州北海岸白', 1.0), ('西班牙瓦倫西亞 白', 1.0)]\n",
      "\n",
      "\n",
      "b1f7077b077152c4f004c7180a59c2e8\n",
      "這是預測的最高前10個\n",
      "[('美國加州中部海岸紅', 5.988499929858045), ('紐西蘭馬爾堡 白', 4.963539352473332), ('義大利托斯卡尼 紅', 4.732255653455943), ('美國加州北海岸紅', 2.969259868825145), ('西班牙利奧哈上利奧哈紅', 2.2801973774524407), ('智利阿空加瓜阿空加瓜白', 2.000329906147155), ('法國波爾多貝沙克–雷奧良紅', 1.9920895201019393), ('法國波爾多上梅多克紅', 1.9822649787191007), ('義大利皮蒙巴羅洛紅', 1.0900330582975004), ('義大利皮蒙蜜思嘉達斯提白', 1.0268758102489988)]\n",
      "這是原本最高的前10個\n",
      "[('美國加州中部海岸紅', 6.0), ('紐西蘭馬爾堡 白', 5.0), ('義大利托斯卡尼 紅', 5.0), ('美國加州北海岸紅', 3.0), ('義大利維內多瓦波里切拉紅', 3.0), ('智利阿空加瓜阿空加瓜白', 2.0), ('法國波爾多貝沙克–雷奧良紅', 2.0), ('澳洲南澳巴羅沙谷白', 2.0), ('義大利皮蒙哥維白', 2.0), ('澳洲西澳 紅', 2.0)]\n",
      "\n",
      "\n",
      "a789b30e0893ab3d4fcdceb18e46a782\n",
      "這是預測的最高前10個\n",
      "[('法國波爾多波雅克紅', 10.989089246161884), ('法國波爾多瑪歌紅', 8.06535344917993), ('法國香檳馬恩河谷白', 7.787341117397126), ('美國加州北海岸紅', 7.029649266649098), ('法國波爾多聖朱里安紅', 6.0177174055326805), ('法國布根地伯恩丘白', 5.954497334284876), ('法國布根地夜丘紅', 5.030691808170849), ('法國波爾多聖愛美濃紅', 4.1285451293663105), ('法國波爾多貝沙克–雷奧良紅', 3.98052971495133), ('法國香檳 白', 3.85226081852085)]\n",
      "這是原本最高的前10個\n",
      "[('法國波爾多波雅克紅', 11.0), ('法國波爾多瑪歌紅', 8.0), ('法國香檳馬恩河谷白', 8.0), ('美國加州北海岸紅', 7.0), ('法國布根地伯恩丘白', 6.0), ('法國波爾多聖朱里安紅', 6.0), ('法國布根地夜丘紅', 5.0), ('法國波爾多貝沙克–雷奧良紅', 4.0), ('法國香檳 白', 4.0), ('義大利托斯卡尼寶格麗紅', 4.0)]\n",
      "\n",
      "\n",
      "723b7787cb8db4e2d5ff7dee3af65a49\n",
      "這是預測的最高前10個\n",
      "[('阿根廷門多薩 紅', 11.109061461255472), ('澳洲南澳巴羅沙谷紅', 3.9316883860596405), ('法國阿爾薩斯 白', 3.889497792189943), ('法國  紅', 2.6811953851045964), ('阿根廷門多薩烏格河谷紅', 2.3531779417314285), ('阿根廷門多薩 白', 1.7557577968964206), ('智利  紅', 1.171771027182765), ('法國  粉紅', 0.9317718033283902), ('澳洲南澳 紅', 0.8935163639814786), ('義大利托斯卡尼 白', 0.6447154914042932)]\n",
      "這是原本最高的前10個\n",
      "[('阿根廷門多薩 紅', 11.0), ('法國薄酒萊摩恭紅', 6.0), ('法國阿爾薩斯 白', 4.0), ('南非西開普區斯泰倫博斯紅', 4.0), ('澳洲南澳巴羅沙谷紅', 4.0), ('智利  紅', 4.0), ('法國布根地夏隆內丘白', 3.0), ('法國  紅', 3.0), ('阿根廷門多薩烏格河谷紅', 3.0), ('法國薄酒萊風車磨坊紅', 3.0)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=50, init='random', random_state=0)\n",
    "\n",
    "# 拟合数据并转换\n",
    "W = model.fit_transform(UI_mat)  \n",
    "H = model.components_            \n",
    "\n",
    "predicted_ratings = np.dot(W, H)\n",
    "predicted_ratings = pd.DataFrame(predicted_ratings, index= UI_mat.index,columns=UI_mat.columns)\n",
    "predict_results(predicted_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVDpp, Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "\n",
    "data_transform_temp = UI_mat.reset_index().melt(id_vars=['客戶代碼'], var_name='細區', value_name='rating')\n",
    "data_transform = data_transform_temp[data_transform_temp['rating']!=0]\n",
    "\n",
    "print(data_transform[\"rating\"].max())\n",
    "print(data_transform['rating'].min())\n",
    "reader = Reader(rating_scale=(1, 420))\n",
    "data = Dataset.load_from_df(data_transform_temp[['客戶代碼', '細區', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_transform.rename(columns={'客戶代碼': 'user_id:token', '細區': 'item_id:token', 'rating':'rating:float'}, inplace=True)\n",
    "data_transform['user_id:token'] = data_transform['user_id:token'].astype(str).str.replace('\"', '').str.replace(' ', '_')\n",
    "data_transform['item_id:token'] = data_transform['item_id:token'].astype(str).str.replace('\"', '').str.replace(' ', '_')\n",
    "data_transform['rating:float'] = data_transform['rating:float'].astype(float)\n",
    "data_transform.to_csv('./icheers/icheers.inter', sep='\\t', index=False)\n",
    "# data_transform.rename(columns={'客戶代碼': 'user_id', '細區': 'item_id', 'rating':'rating'}, inplace=True)\n",
    "# data_transform.to_csv('./my_dataset/my_dataset.inter', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_epochs': [20, 50, 100], \n",
    "    'lr_all': [0.005, 0.01, 0.1],\n",
    "    'n_factors': [50,100, 200, 300],\n",
    "    'reg_all': [0.02, 0.05]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(SVDpp, param_grid, measures=['rmse'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "print('Best RMSE:', gs.best_score['rmse'])\n",
    "print('Best parameters:', gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVDpp(n_epochs=gs.best_params['rmse']['n_epochs'], \n",
    "             lr_all=gs.best_params['rmse']['lr_all'],\n",
    "             n_factors=gs.best_params['rmse']['n_factors'],\n",
    "             reg_all=gs.best_params['rmse']['reg_all'])\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(data, test_size=.3)\n",
    "model = SVDpp()\n",
    "model.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = data_transform_temp['客戶代碼'].unique()\n",
    "all_items = data_transform_temp['細區'].unique()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for user in all_users:\n",
    "    for item in all_items:\n",
    "        pred = model.predict(user, item)\n",
    "        predictions.append([user, item, pred.est])\n",
    "\n",
    "df_predictions = pd.DataFrame(predictions, columns=['客戶代碼', '細區', 'rating'])\n",
    "pivot_table = df_predictions.pivot(index='客戶代碼', columns='細區', values='rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another SVD++ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mpltw\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#plt.style.use('seaborn')\n",
    "from Sales_Pipeline import pipeline, user_item_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "user_area = UI_mat.values\n",
    "user_area_mean = user_area.mean()\n",
    "\n",
    "user_area_centered = user_area - user_area_mean\n",
    "user_area_centered_df = pd.DataFrame(user_area_centered, index= UI_mat.index, columns= UI_mat.columns)\n",
    "\n",
    "# set initial status\n",
    "b_user = np.zeros(UI_mat.shape[0])\n",
    "b_item = np.zeros(UI_mat.shape[1])\n",
    "row_num = UI_mat.shape[0]\n",
    "column_num = UI_mat.shape[1]\n",
    "threshold = 1e-6\n",
    "max_iterations = 100\n",
    "alpha = 0.01\n",
    "lambda_ = 0.02\n",
    "J_init = float('inf')\n",
    "iteration = 0\n",
    "converged = False\n",
    "\n",
    "# update\n",
    "while iteration < max_iterations and not converged:\n",
    "    current_J = 0\n",
    "    \n",
    "    for i in range(row_num):\n",
    "        for j in range(column_num):\n",
    "            #calculate error\n",
    "            e_ij = user_area_centered[i][j] - b_user[i] - b_item[j]\n",
    "            \n",
    "            #update b_user and b_item\n",
    "            b_user[i] += alpha * (e_ij - (lambda_ * b_user[i]))\n",
    "            b_item[j] += alpha * (e_ij - (lambda_ * b_item[j]))\n",
    "            \n",
    "            current_J += e_ij**2\n",
    "            \n",
    "    current_J += lambda_ /2 * ((np.sum(b_user**2)) + np.sum(b_item**2))\n",
    "    \n",
    "    if abs(J_init - current_J) < threshold:\n",
    "        converged = True\n",
    "    else:\n",
    "        J_init = current_J\n",
    "        iteration += 1\n",
    "    \n",
    "B_ij = np.array([[x+y for y in b_item] for x in b_user])\n",
    "\n",
    "item_similarity = cosine_similarity(UI_mat.T)\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index= UI_mat.columns, columns=UI_mat.columns)\n",
    "\n",
    "ratings_np = np.around(user_area_centered_df.to_numpy(),2)\n",
    "similarity_np = np.around(item_similarity_df.to_numpy(),2)\n",
    "UI_mat_np = np.around(UI_mat.to_numpy(),4)\n",
    "ratings_np[np.isnan(ratings_np)] = 0\n",
    "similarity_np[np.isnan(similarity_np)] = 0\n",
    "\n",
    "# Number of latent factors\n",
    "latent_factor = 2\n",
    "\n",
    "w_item_np = np.around(np.random.rand(ratings_np.shape[1], ratings_np.shape[1]) * 1, 4)\n",
    "c_lj_np = np.around(np.random.rand(ratings_np.shape[1], ratings_np.shape[1]) * 1, 4)\n",
    "B_il_np = np.around(B_ij,4)\n",
    "U_np = np.around(np.random.rand(ratings_np.shape[0], latent_factor + 2) * 1,4)\n",
    "V_np = np.around(np.random.rand(ratings_np.shape[1], latent_factor + 2) * 1,4)\n",
    "Y_np = np.around(np.random.rand(ratings_np.shape[1], latent_factor + 2) * 1,4)\n",
    "r_hat_np = np.ones((ratings_np.shape[0], ratings_np.shape[1]))\n",
    "\n",
    "U_np[:, -2] = 1  \n",
    "V_np[:, -1] = 1 \n",
    "Y_np[:, -2:] = 0\n",
    "\n",
    "# Parameters\n",
    "alpha_1 = 0.00001\n",
    "alpha_2  = 0.00001\n",
    "lambda_1 = 0.00001\n",
    "lambda_2 = 0.00001\n",
    "\n",
    "K = 10\n",
    "\n",
    "def calculate_sum_Yhs_over_sqrt_Ii_np(ratings_np, user_index, Y_np):\n",
    "    non_zero_indices = ratings_np[user_index, :] > 0\n",
    "    num_non_zero_ratings = non_zero_indices.sum()\n",
    "    if num_non_zero_ratings == 0:\n",
    "        return 0\n",
    "\n",
    "    sum_Yhs_columns = np.around(np.sum(Y_np[non_zero_indices], axis=0),decimals=4)\n",
    "    # Clip the values to prevent overflow before division\n",
    "    sum_Yhs_columns = np.clip(sum_Yhs_columns, -1e4, 1e4)\n",
    "    # Limit the precision to avoid overflow issues\n",
    "    sum_Yhs_columns = np.around(sum_Yhs_columns, decimals=4)\n",
    "    \n",
    "    sqrt_non_zero_indices = np.around(np.sqrt(num_non_zero_ratings),decimals=4)\n",
    "    final_sum_Yhs = np.around(sum_Yhs_columns / sqrt_non_zero_indices, decimals=4)\n",
    "    Y_sum = np.around(np.sum(final_sum_Yhs), decimals=4)\n",
    "    return Y_sum\n",
    "\n",
    "def predict_rating_np(U_np, V_np, Y_np, user_index, item_index, w_item_np, B_il_np, c_lj_np, latent_factor, K):\n",
    "    neighbors_indices = np.argsort(-similarity_np[item_index])[:K]\n",
    "    neighbors_ratings = ratings_np[user_index, neighbors_indices]\n",
    "    neighbors_biases = B_il_np[user_index, neighbors_indices]\n",
    "    sqrt_neighbor_len = np.around(np.sqrt(len(neighbors_indices)),decimals=2)\n",
    "    \n",
    "    sum_part_first = np.around(np.sum(w_item_np[item_index, neighbors_indices] * (neighbors_ratings - neighbors_biases)), decimals=4)\n",
    "    \n",
    "    sum_part_last = np.around(np.sum(c_lj_np[neighbors_indices, item_index]), decimals=4)\n",
    "    \n",
    "    if sqrt_neighbor_len == 0:\n",
    "        sum_part_neighbor = 0\n",
    "    else:\n",
    "        sum_part_neighbor = np.around(((sum_part_first + sum_part_last) / sqrt_neighbor_len), decimals=4)\n",
    "    sum_part_neighbor = np.around(sum_part_neighbor, decimals=4)\n",
    "\n",
    "    Y_sum = calculate_sum_Yhs_over_sqrt_Ii_np(ratings_np, user_index, Y_np)\n",
    "    Y_sum = np.around(Y_sum, decimals=4)\n",
    "    sum_part_latent = np.around(np.dot(U_np[user_index, :latent_factor + 2] + Y_sum, V_np[item_index, :latent_factor + 2]), decimals=4)\n",
    "    prediction = sum_part_neighbor + sum_part_latent\n",
    "    prediction = np.around(prediction, decimals=4)\n",
    "    \n",
    "    return prediction, Y_sum\n",
    "\n",
    "def sgd_step_np(U_np, V_np, Y_np, w_item_np, B_il_np, ratings_np, similarity_np, alpha_1, alpha_2, lambda_1, lambda_2, K, c_lj_np, latent_factor):\n",
    "    U_np = np.nan_to_num(U_np)\n",
    "    V_np = np.nan_to_num(V_np)\n",
    "    Y_np = np.nan_to_num(Y_np)\n",
    "    ratings_np = np.nan_to_num(ratings_np)\n",
    "    similarity_np = np.nan_to_num(similarity_np)\n",
    "    B_il_np = np.nan_to_num(B_il_np)\n",
    "    \n",
    "    users, items = np.nonzero(ratings_np)\n",
    "    \n",
    "    for user_index, item_index in zip(users, items):\n",
    "        prediction, Y_sum = predict_rating_np(U_np, V_np, Y_np, user_index, item_index, w_item_np, B_il_np, c_lj_np, latent_factor, K)\n",
    "        error = np.around((ratings_np[user_index, item_index] - prediction), decimals=4)\n",
    "        \n",
    "        # Validate prediction and error to avoid NaN propagation\n",
    "        if np.isnan(prediction) or np.isinf(prediction) or np.isnan(error) or np.isinf(error):\n",
    "            error = 0\n",
    "        \n",
    "        rated_indices = ratings_np[user_index, :] > 0\n",
    "        sqrt_Iu = np.sqrt(np.sum(rated_indices))\n",
    "        sqrt_Iu = np.around(sqrt_Iu, decimals=4)\n",
    "        \n",
    "        # Update U\n",
    "        U_update = np.around(alpha_1 * (error * V_np[item_index, :] - lambda_1 * U_np[user_index, :]),decimals=4)\n",
    "        U_np[user_index, :] += np.around(np.nan_to_num(U_update), decimals=4)\n",
    "        \n",
    "        # Calculate Y's sum and update V\n",
    "        if sqrt_Iu > 0:\n",
    "            V_update = np.around(alpha_1 * (error * (U_np[user_index, :] + Y_sum) - lambda_1 * V_np[item_index, :]),decimals=4)\n",
    "            V_np[item_index, :] += np.around(np.nan_to_num(V_update), decimals=4)\n",
    "\n",
    "        # Update Y\n",
    "\n",
    "        if sqrt_Iu == 0:\n",
    "            Y_update = np.around((alpha_1) * ( - lambda_1 * Y_np[rated_indices, :]), decimals=4)\n",
    "            Y_np[rated_indices, :] += np.around(np.nan_to_num(Y_update), decimals=4)\n",
    "            \n",
    "        else:\n",
    "            Y_update = np.around((alpha_1) * ( np.around((error * V_np[item_index, :] / sqrt_Iu),decimals=4) - lambda_1 * Y_np[rated_indices, :]), decimals=4)\n",
    "            Y_np[rated_indices, :] += np.around(np.nan_to_num(Y_update), decimals=4)\n",
    "            \n",
    "        neighbors_indices = np.argsort(-similarity_np[item_index, :])[:K]\n",
    "        neighbors_indices = neighbors_indices[ratings_np[user_index, neighbors_indices] > 0]\n",
    "        sqrt_neighbor_len = np.around(np.sqrt(len(neighbors_indices)), decimals=4)\n",
    "    \n",
    "        if sqrt_neighbor_len == 0:\n",
    "            \n",
    "            w_item_update = np.around(alpha_2 * ( - lambda_2 * w_item_np[item_index, neighbors_indices]),decimals=4)\n",
    "            w_item_np[item_index, neighbors_indices] += np.around(np.nan_to_num(w_item_update),decimals=4)\n",
    "            \n",
    "            c_lj_update = np.around(alpha_2 * (- lambda_2 * c_lj_np[neighbors_indices, item_index]),decimals=4)\n",
    "            c_lj_np[neighbors_indices, item_index] += np.around(np.nan_to_num(c_lj_update),decimals=4)\n",
    "        else:\n",
    "            w_item_update = np.around(alpha_2 * np.around(((error * (ratings_np[user_index, neighbors_indices] - B_il_np[user_index, neighbors_indices]) / sqrt_neighbor_len) - lambda_2 * w_item_np[item_index, neighbors_indices]), decimals=4), decimals=4)\n",
    "            w_item_np[item_index, neighbors_indices] += np.around(np.nan_to_num(w_item_update), decimals=4)\n",
    "            \n",
    "            c_lj_update = np.around(alpha_2 * ((error / sqrt_neighbor_len) - lambda_2 * c_lj_np[neighbors_indices, item_index]),decimals=4)\n",
    "            c_lj_np[neighbors_indices, item_index] += np.around(np.nan_to_num(c_lj_update),decimals=4)\n",
    "        \n",
    "        U_np[:, -2] = 1  \n",
    "        V_np[:, -1] = 1 \n",
    "        Y_np[:, -2:] = 0\n",
    "\n",
    "        \n",
    "    return U_np, V_np, Y_np, w_item_np, c_lj_np\n",
    "\n",
    "for _ in range(100):\n",
    "    U_np, V_np, Y_np, w_item_np, c_lj_np = sgd_step_np(\n",
    "        U_np, V_np, Y_np, w_item_np, B_il_np, ratings_np, similarity_np, \n",
    "        alpha_1, alpha_2, lambda_1, lambda_2, K, c_lj_np, latent_factor)\n",
    "\n",
    "    U_np = np.nan_to_num(U_np)\n",
    "    V_np = np.nan_to_num(V_np)\n",
    "    Y_np = np.nan_to_num(Y_np)\n",
    "    ratings_np = np.nan_to_num(ratings_np)\n",
    "    similarity_np = np.nan_to_num(similarity_np)\n",
    "    B_il_np = np.nan_to_num(B_il_np)\n",
    "    c_lj_np = np.nan_to_num(c_lj_np)\n",
    "    \n",
    "def predict_all_ratings_np(ratings_np, U_np, V_np, Y_np, w_item_np, B_il_np, c_lj_np, latent_factor, K):\n",
    "    num_users, num_items = ratings_np.shape\n",
    "    r_hat_np = np.zeros((num_users, num_items))\n",
    "\n",
    "    for user in range(num_users):\n",
    "        for item in range(num_items):\n",
    "            # Call a function that needs to be vectorized as much as possible\n",
    "            r_hat_np[user, item], no = predict_rating_np(U_np, V_np, Y_np, user, item, w_item_np, B_il_np, c_lj_np, latent_factor, K)\n",
    "            \n",
    "    return r_hat_np\n",
    "\n",
    "rate_hat = predict_all_ratings_np(ratings_np, U_np, V_np, Y_np, w_item_np, B_il_np, c_lj_np, latent_factor, K)\n",
    "rate_hat_df = pd.DataFrame(rate_hat, index= UI_mat.index, columns= UI_mat.columns)\n",
    "rate_hat_df.to_excel('SVD++_predic_100loop.xlsx')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.general_recommender import FISM\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n",
    "from recbole.utils.case_study import full_sort_topk\n",
    "from recbole.model.general_recommender import SLIMElastic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model='SLIMElastic', dataset='icheers', config_file_list = ['/home/r12323007/work_icheers/2024june/my_dataset.yaml'])\n",
    "dataset = create_dataset(config)\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "logger.info(dataset)\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "model = SLIMElastic(config, train_data.dataset)\n",
    "trainer = Trainer(config, model)\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "test_result = trainer.evaluate(test_data)\n",
    "logger.info(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from recbole.quick_start import load_data_and_model\n",
    "from recbole.utils.case_study import full_sort_topk, full_sort_scores\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(\n",
    "    model_file='/home/r12323007/work_icheers/2024june/saved/SLIMElastic-Jul-17-2024_21-46-21.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0516, 0.0434, 0.0415, 0.0413, 0.0340, 0.0289, 0.0217, 0.0208, 0.0186,\n",
      "         0.0174],\n",
      "        [0.2093, 0.2069, 0.1458, 0.0990, 0.0809, 0.0757, 0.0676, 0.0637, 0.0591,\n",
      "         0.0529],\n",
      "        [0.0272, 0.0109, 0.0089, 0.0075, 0.0066, 0.0063, 0.0057, 0.0054, 0.0054,\n",
      "         0.0031],\n",
      "        [0.1213, 0.1137, 0.1117, 0.0908, 0.0812, 0.0784, 0.0777, 0.0704, 0.0647,\n",
      "         0.0642],\n",
      "        [0.1449, 0.1157, 0.1089, 0.0867, 0.0838, 0.0808, 0.0689, 0.0631, 0.0594,\n",
      "         0.0592],\n",
      "        [0.0386, 0.0372, 0.0220, 0.0202, 0.0193, 0.0188, 0.0177, 0.0170, 0.0140,\n",
      "         0.0132]])\n",
      "[['法國布根地_白' '法國布根地夜丘紅' '法國布根地伯恩丘紅' '美國加州北海岸紅' '法國香檳_白' '紐西蘭馬爾堡_白'\n",
      "  '義大利托斯卡尼_紅' '法國布根地馬貢白' '法國波爾多_紅' '法國隆河谷_紅']\n",
      " ['法國波爾多聖愛斯臺夫紅' '義大利托斯卡尼_紅' '紐西蘭馬爾堡_白' '法國隆河谷教皇新堡紅' '法國香檳_粉紅' '法國薄酒萊_紅'\n",
      "  '義大利皮蒙巴巴瑞斯科紅' '美國加州中部海岸紅' '阿根廷門多薩_紅' '法國波爾多玻美侯紅']\n",
      " ['美國加州北海岸紅' '紐西蘭馬爾堡_白' '法國布根地_白' '法國香檳_白' '義大利托斯卡尼_紅' '法國布根地夏布利白'\n",
      "  '法國布根地夜丘紅' '法國布根地馬貢白' '法國布根地伯恩丘紅' '澳洲南澳巴羅沙谷紅']\n",
      " ['法國香檳_白' '法國布根地_紅' '法國布根地夜丘紅' '澳洲南澳巴羅沙谷紅' '法國波爾多波雅克紅' '法國布根地伯恩丘紅'\n",
      "  '法國波爾多聖愛美濃紅' '法國波爾多聖愛斯臺夫紅' '法國波爾多瑪歌紅' '美國加州北海岸白']\n",
      " ['法國布根地_紅' '法國波爾多上梅多克紅' '澳洲南澳巴羅沙谷紅' '法國布根地_白' '法國隆河谷教皇新堡紅' '紐西蘭馬爾堡_白'\n",
      "  '法國香檳白丘白' '美國加州北海岸白' '法國布根地夏布利白' '義大利皮蒙巴巴瑞斯科紅']\n",
      " ['義大利托斯卡尼_紅' '美國加州北海岸紅' '法國香檳_白' '阿根廷門多薩_紅' '智利中央谷地邁波紅' '澳洲南澳麥克拉倫谷紅'\n",
      "  '法國布根地夜丘紅' '紐西蘭馬爾堡_白' '法國波爾多聖愛美濃紅' '法國布根地_紅']]\n"
     ]
    }
   ],
   "source": [
    "picked_user_list = ['231228b77124b1331fbee2abfc9cf923', 'afb8a6cf419846dccdaca13bb275de65', '3b9abfef5b9dbfd31c664470dc528319',\n",
    "                     'b1f7077b077152c4f004c7180a59c2e8', 'a789b30e0893ab3d4fcdceb18e46a782', '723b7787cb8db4e2d5ff7dee3af65a49']\n",
    "uid_field = dataset.uid_field\n",
    "uid_series = dataset.token2id(uid_field, picked_user_list)\n",
    "\n",
    "topk_scores, topk_item_ids = full_sort_topk(\n",
    "    uid_series, model, test_data, k=10, device=config[\"device\"]\n",
    ")\n",
    "\n",
    "print(topk_scores)\n",
    "\n",
    "item_field = dataset.iid_field\n",
    "topk_external_item_ids = dataset.id2token(item_field, topk_item_ids)\n",
    "\n",
    "print(topk_external_item_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another SLIM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained SLIM model coefficients:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def train_slim_model(data, alpha=0.1, l1_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Train a SLIM model using ElasticNet.\n",
    "    \n",
    "    :param data: The user-item interaction matrix (numpy array).\n",
    "    :param alpha: Regularization strength.\n",
    "    :param l1_ratio: The ElasticNet mixing parameter, with 0 <= l1_ratio <= 1.\n",
    "                     l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1 penalty.\n",
    "    :return: A trained SLIM model (coefficients matrix).\n",
    "    \"\"\"\n",
    "    # Number of items\n",
    "    num_items = data.shape[1]\n",
    "    \n",
    "    # Model coefficients matrix\n",
    "    W = np.zeros((num_items, num_items))\n",
    "    \n",
    "    # Train a model for each item\n",
    "    for item in range(num_items):\n",
    "        # Create target column\n",
    "        y = data[:, item]\n",
    "        \n",
    "        # Create feature matrix\n",
    "        X = np.delete(data, item, axis=1)\n",
    "        \n",
    "        # Define the model\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, positive=True, fit_intercept=False, copy_X=True)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        # Store the coefficients\n",
    "        W[:, item] = np.insert(model.coef_, item, 0)\n",
    "    \n",
    "    return W\n",
    "\n",
    "# Example data: User-item interaction matrix\n",
    "data = np.array(UI_mat)\n",
    "# Train the model\n",
    "W = train_slim_model(data)\n",
    "# Predict scores for all users\n",
    "predicted_scores = np.dot(data, W)\n",
    "predicted_SLIM_ratings = pd.DataFrame(predicted_scores, index= UI_mat.index,columns=UI_mat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_SLIM_ratings.to_csv('/home/r12323007/work_icheers/2024june/SLIM_model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model='FISM', dataset='icheers', config_file_list = ['/home/r12323007/work_icheers/2024june/my_dataset.yaml'])\n",
    "dataset = create_dataset(config)\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "logger.info(dataset)\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "model = FISM(config, train_data.dataset)\n",
    "trainer = Trainer(config, model)\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "test_result = trainer.evaluate(test_data)\n",
    "logger.info(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from recbole.quick_start import load_data_and_model\n",
    "from recbole.utils.case_study import full_sort_topk, full_sort_scores\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(\n",
    "    model_file='/home/r12323007/work_icheers/2024june/saved/FISM-Jul-17-2024_21-53-26.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6814, 0.6773, 0.6771, 0.6642, 0.6623, 0.6623, 0.6610, 0.6600, 0.6581,\n",
      "         0.6529],\n",
      "        [0.3043, 0.3030, 0.3019, 0.2948, 0.2791, 0.2515, 0.2451, 0.2406, 0.2344,\n",
      "         0.2324],\n",
      "        [0.6240, 0.6199, 0.6197, 0.6089, 0.6068, 0.6050, 0.6050, 0.6036, 0.6026,\n",
      "         0.6007],\n",
      "        [0.3431, 0.3390, 0.3280, 0.3259, 0.3228, 0.3217, 0.3198, 0.3144, 0.3091,\n",
      "         0.3091],\n",
      "        [0.3548, 0.3509, 0.3509, 0.3496, 0.3412, 0.3257, 0.3241, 0.3145, 0.3123,\n",
      "         0.3070],\n",
      "        [0.5136, 0.5095, 0.5093, 0.4985, 0.4964, 0.4945, 0.4945, 0.4932, 0.4922,\n",
      "         0.4903]])\n",
      "[['法國香檳_白' '法國布根地夜丘紅' '美國加州北海岸紅' '法國波爾多波雅克紅' '法國布根地_白' '紐西蘭馬爾堡_白'\n",
      "  '法國薄酒萊_紅' '法國波爾多聖愛斯臺夫紅' '法國布根地伯恩丘紅' '義大利托斯卡尼_紅']\n",
      " ['紐西蘭馬爾堡_白' '法國薄酒萊_紅' '法國波爾多聖愛斯臺夫紅' '義大利托斯卡尼_紅' '義大利皮蒙蜜思嘉達斯提白' '法國香檳_粉紅'\n",
      "  '阿根廷門多薩_紅' '法國隆河谷教皇新堡紅' '日本甲信越地方山梨縣白' '義大利皮蒙巴巴瑞斯科紅']\n",
      " ['法國香檳_白' '法國布根地夜丘紅' '美國加州北海岸紅' '法國布根地_紅' '法國波爾多波雅克紅' '法國布根地_白'\n",
      "  '紐西蘭馬爾堡_白' '法國薄酒萊_紅' '法國波爾多聖愛斯臺夫紅' '法國布根地伯恩丘紅']\n",
      " ['法國香檳_白' '法國布根地夜丘紅' '法國布根地_紅' '法國波爾多波雅克紅' '法國薄酒萊_紅' '法國波爾多聖愛斯臺夫紅'\n",
      "  '法國布根地伯恩丘紅' '澳洲南澳巴羅沙谷紅' '法國波爾多瑪歌紅' '法國波爾多聖愛美濃紅']\n",
      " ['法國布根地_紅' '法國布根地_白' '紐西蘭馬爾堡_白' '法國薄酒萊_紅' '澳洲南澳巴羅沙谷紅' '義大利皮蒙蜜思嘉達斯提白'\n",
      "  '法國波爾多_紅' '法國波爾多上梅多克紅' '法國波爾多_白' '美國加州北海岸白']\n",
      " ['法國香檳_白' '法國布根地夜丘紅' '美國加州北海岸紅' '法國布根地_紅' '法國波爾多波雅克紅' '法國布根地_白'\n",
      "  '紐西蘭馬爾堡_白' '法國薄酒萊_紅' '法國波爾多聖愛斯臺夫紅' '法國布根地伯恩丘紅']]\n"
     ]
    }
   ],
   "source": [
    "picked_user_list = ['231228b77124b1331fbee2abfc9cf923', 'afb8a6cf419846dccdaca13bb275de65', '3b9abfef5b9dbfd31c664470dc528319',\n",
    "                     'b1f7077b077152c4f004c7180a59c2e8', 'a789b30e0893ab3d4fcdceb18e46a782', '723b7787cb8db4e2d5ff7dee3af65a49']\n",
    "uid_field = dataset.uid_field\n",
    "uid_series = dataset.token2id(uid_field, picked_user_list)\n",
    "\n",
    "topk_scores, topk_item_ids = full_sort_topk(\n",
    "    uid_series, model, test_data, k=10, device=config[\"device\"]\n",
    ")\n",
    "\n",
    "print(topk_scores)\n",
    "\n",
    "item_field = dataset.iid_field\n",
    "topk_external_item_ids = dataset.id2token(item_field, topk_item_ids)\n",
    "\n",
    "print(topk_external_item_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another FISM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 completed.\n",
      "Epoch 2/20 completed.\n",
      "Epoch 3/20 completed.\n",
      "Epoch 4/20 completed.\n",
      "Epoch 5/20 completed.\n",
      "Epoch 6/20 completed.\n",
      "Epoch 7/20 completed.\n",
      "Epoch 8/20 completed.\n",
      "Epoch 9/20 completed.\n",
      "Epoch 10/20 completed.\n",
      "Epoch 11/20 completed.\n",
      "Epoch 12/20 completed.\n",
      "Epoch 13/20 completed.\n",
      "Epoch 14/20 completed.\n",
      "Epoch 15/20 completed.\n",
      "Epoch 16/20 completed.\n",
      "Epoch 17/20 completed.\n",
      "Epoch 18/20 completed.\n",
      "Epoch 19/20 completed.\n",
      "Epoch 20/20 completed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FISM:\n",
    "    def __init__(self, num_users, num_items, latent_dim=50, alpha=0.5, learning_rate=0.001, reg=0.1, epochs=20):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim = latent_dim\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg = reg\n",
    "        self.epochs = epochs\n",
    "        self.P = np.random.normal(scale=1.0/latent_dim, size=(num_items, latent_dim))\n",
    "        self.Q = np.random.normal(scale=1.0/latent_dim, size=(num_items, latent_dim))\n",
    "\n",
    "    def train(self, user_item_matrix):\n",
    "        for epoch in range(self.epochs):\n",
    "            for u in range(self.num_users):\n",
    "                items_u = np.where(user_item_matrix[u, :] > 0)[0]\n",
    "                if len(items_u) == 0:\n",
    "                    continue\n",
    "                for i in items_u:\n",
    "                    item_set = set(items_u) - {i}\n",
    "                    if len(item_set) == 0:\n",
    "                        continue\n",
    "                    q_i = self.Q[i]\n",
    "                    p_u = np.sum(self.P[list(item_set)], axis=0) / (len(item_set) ** self.alpha)\n",
    "                    if np.any(np.isnan(p_u)) or np.any(np.isnan(q_i)):\n",
    "                        continue\n",
    "                    error = user_item_matrix[u, i] - np.dot(p_u, q_i)\n",
    "                    if np.isnan(error):\n",
    "                        continue\n",
    "                    self.Q[i] += self.learning_rate * (error * p_u - self.reg * q_i)\n",
    "                    for j in item_set:\n",
    "                        self.P[j] += self.learning_rate * (error * q_i / (len(item_set) ** self.alpha) - self.reg * self.P[j])\n",
    "            print(f'Epoch {epoch + 1}/{self.epochs} completed.')\n",
    "\n",
    "    def predict(self, user_item_matrix):\n",
    "        predictions = np.zeros((self.num_users, self.num_items))\n",
    "        for u in range(self.num_users):\n",
    "            items_u = np.where(user_item_matrix[u, :] > 0)[0]\n",
    "            if len(items_u) == 0:\n",
    "                continue\n",
    "            for i in range(self.num_items):\n",
    "                item_set = set(items_u)\n",
    "                if i in item_set:\n",
    "                    item_set.remove(i)\n",
    "                if len(item_set) == 0:\n",
    "                    continue\n",
    "                p_u = np.sum(self.P[list(item_set)], axis=0) / (len(item_set) ** self.alpha)\n",
    "                if np.any(np.isnan(p_u)) or np.any(np.isnan(self.Q[i])):\n",
    "                    predictions[u, i] = np.nan\n",
    "                else:\n",
    "                    predictions[u, i] = np.dot(p_u, self.Q[i])\n",
    "        return predictions\n",
    "\n",
    "user_item_matrix = np.array(UI_mat)\n",
    "\n",
    "num_users, num_items = user_item_matrix.shape\n",
    "fism = FISM(num_users, num_items)\n",
    "fism.train(user_item_matrix)\n",
    "predictions = fism.predict(user_item_matrix)\n",
    "\n",
    "predicted_FISM_ratings = pd.DataFrame(predictions, index= UI_mat.index,columns=UI_mat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLORMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10403, 738)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def select_anchor_points(rating_matrix, num_anchors=3):\n",
    "    num_users = rating_matrix.shape[0]\n",
    "    return np.random.choice(num_users, num_anchors, replace=False)\n",
    "\n",
    "def construct_submatrix(rating_matrix, anchor_point, threshold=0.5):\n",
    "    user_sim = cosine_similarity(rating_matrix)\n",
    "    similar_users = np.where(user_sim[anchor_point] > threshold)[0]\n",
    "    submatrix = rating_matrix[similar_users]\n",
    "    \n",
    "    if submatrix.nnz == 0 or submatrix.shape[0] < 2 or submatrix.shape[1] < 2:\n",
    "        return None, None\n",
    "    return submatrix, similar_users\n",
    "\n",
    "def decompose_matrix(rating_matrix, n_components=2):\n",
    "    if n_components <= 0 or n_components >= min(rating_matrix.shape):\n",
    "        n_components = min(rating_matrix.shape) - 1\n",
    "    U, S, Vt = svds(rating_matrix, k=n_components)\n",
    "    return U, np.diag(S), Vt\n",
    "\n",
    "def predict_ratings(U, S, Vt):\n",
    "    return np.dot(U, np.dot(S, Vt))\n",
    "\n",
    "def process_anchor(rating_matrix, anchor, threshold, n_components):\n",
    "    submatrix, similar_users = construct_submatrix(rating_matrix, anchor, threshold)\n",
    "    if submatrix is not None and similar_users is not None:\n",
    "        try:\n",
    "            U, S, Vt = decompose_matrix(submatrix, n_components)\n",
    "            submatrix_pred = predict_ratings(U, S, Vt)\n",
    "            return submatrix_pred, similar_users\n",
    "        except ValueError as e:\n",
    "            return np.zeros(rating_matrix.shape), np.array([])\n",
    "    return np.zeros(rating_matrix.shape), np.array([])\n",
    "\n",
    "def llorma(rating_matrix, num_anchors=3, threshold=0.5, n_components=2):\n",
    "    anchor_points = select_anchor_points(rating_matrix, num_anchors)\n",
    "    predictions = np.zeros(rating_matrix.shape, dtype=float)\n",
    "    weights = np.zeros(rating_matrix.shape, dtype=float)\n",
    "    \n",
    "    with Pool() as pool:\n",
    "        results = pool.starmap(process_anchor, [(rating_matrix, anchor, threshold, n_components) for anchor in anchor_points])\n",
    "    \n",
    "    for submatrix_pred, similar_users in results:\n",
    "        if len(similar_users) > 0:\n",
    "            for i, user in enumerate(similar_users):\n",
    "                for j in range(rating_matrix.shape[1]):\n",
    "                    if rating_matrix[user, j] > 0:\n",
    "                        predictions[user, j] += submatrix_pred[i, j]\n",
    "                        weights[user, j] += 1\n",
    "    \n",
    "    final_predictions = np.divide(predictions, weights, out=np.zeros_like(predictions), where=weights != 0)\n",
    "    return final_predictions\n",
    "\n",
    "rating_matrix = csr_matrix(UI_mat.values)\n",
    "print(rating_matrix.shape)\n",
    "predicted_ratings = llorma(rating_matrix, num_anchors=50, threshold=0.2, n_components=100)\n",
    "predicted_ratings_df = pd.DataFrame(predicted_ratings, index = UI_mat.index, columns= UI_mat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231228b77124b1331fbee2abfc9cf923\n",
      "這是預測的最高前10個\n",
      "[('法國布根地 白', 4.978569218246232), ('法國布根地 紅', 0.9986796310555275), ('法國布根地夏布利白', 0.9896205647716101), ('美國加州北海岸白', 0.9825376892531215), ('阿根廷門多薩San Carlos紅', 0.0), ('阿根廷門多薩Santa Rosa紅', 0.0), ('阿根廷門多薩Tunuyan紅', 0.0), ('阿根廷門多薩Tupungato - Valle de Tupungato 白', 0.0), ('阿根廷門多薩烏格河谷白', 0.0), ('阿根廷門多薩烏格河谷紅', 0.0)]\n",
      "這是原本最高的前10個\n",
      "[('法國布根地 白', 5.0), ('法國布根地 紅', 1.0), ('法國布根地夏布利白', 1.0), ('美國加州北海岸白', 1.0)]\n",
      "\n",
      "\n",
      "afb8a6cf419846dccdaca13bb275de65\n",
      "這是預測的最高前10個\n",
      "[('黎巴嫩  紅', 11.064970585240488), ('法國布根地 紅', 10.004847921550018), ('法國隆河谷隆河丘紅', 8.021680247982053), ('法國波爾多波雅克紅', 7.00998315357616), ('澳洲南澳巴羅沙谷紅', 7.0081089619808745), ('法國香檳 白', 6.999962196120359), ('西班牙利奧哈上利奧哈紅', 6.026312576827752), ('法國布根地上夜丘紅', 6.009095229769975), ('美國加州 白', 5.966814127804623), ('法國布根地 白', 5.009525406789947)]\n",
      "這是原本最高的前10個\n",
      "[('黎巴嫩  紅', 11.0), ('法國布根地 紅', 10.0), ('法國隆河谷隆河丘紅', 8.0), ('法國香檳 白', 7.0), ('澳洲南澳巴羅沙谷紅', 7.0), ('法國波爾多波雅克紅', 7.0), ('美國加州 白', 6.0), ('法國布根地上夜丘紅', 6.0), ('西班牙利奧哈上利奧哈紅', 6.0), ('法國布根地夜丘紅', 5.0)]\n",
      "\n",
      "\n",
      "3b9abfef5b9dbfd31c664470dc528319\n",
      "這是預測的最高前10個\n",
      "[('美國加州北海岸白', 0.9999341719193791), ('法國布根地夜丘白', 0.7541876131459128), ('台灣彰化二林紅', 0.5172448867926693), ('法國羅亞爾河谷蜜思卡得粉紅', 0.42320225030333897), ('西班牙瓦倫西亞 白', 0.30610536437036223), ('紐西蘭  白', 0.25895462363792776), ('阿根廷門多薩San Carlos紅', 0.0), ('阿根廷門多薩Santa Rosa紅', 0.0), ('阿根廷門多薩Tunuyan紅', 0.0), ('阿根廷門多薩Tupungato - Valle de Tupungato 白', 0.0)]\n",
      "這是原本最高的前10個\n",
      "[('台灣彰化二林紅', 1.0), ('法國布根地夜丘白', 1.0), ('法國羅亞爾河谷蜜思卡得粉紅', 1.0), ('紐西蘭  白', 1.0), ('美國加州北海岸白', 1.0), ('西班牙瓦倫西亞 白', 1.0)]\n",
      "\n",
      "\n",
      "b1f7077b077152c4f004c7180a59c2e8\n",
      "這是預測的最高前10個\n",
      "[('美國加州中部海岸紅', 6.03118255021444), ('義大利托斯卡尼 紅', 5.022411503992264), ('紐西蘭馬爾堡 白', 5.0028344077714255), ('美國加州北海岸紅', 3.0077169536994814), ('義大利維內多瓦波里切拉紅', 2.8070888102044966), ('法國波爾多貝沙克–雷奧良紅', 2.0602619510978584), ('西班牙利奧哈 紅', 2.051565531653702), ('西班牙卡斯提亞–雷昂斗羅河岸紅', 2.0170583573413134), ('法國波爾多上梅多克紅', 2.004328075368973), ('西班牙利奧哈上利奧哈紅', 2.003759553980547)]\n",
      "這是原本最高的前10個\n",
      "[('美國加州中部海岸紅', 6.0), ('紐西蘭馬爾堡 白', 5.0), ('義大利托斯卡尼 紅', 5.0), ('美國加州北海岸紅', 3.0), ('義大利維內多瓦波里切拉紅', 3.0), ('智利阿空加瓜阿空加瓜白', 2.0), ('法國波爾多貝沙克–雷奧良紅', 2.0), ('澳洲南澳巴羅沙谷白', 2.0), ('義大利皮蒙哥維白', 2.0), ('澳洲西澳 紅', 2.0)]\n",
      "\n",
      "\n",
      "a789b30e0893ab3d4fcdceb18e46a782\n",
      "這是預測的最高前10個\n",
      "[('法國波爾多波雅克紅', 11.001397935337183), ('法國波爾多瑪歌紅', 7.998348562712892), ('法國香檳馬恩河谷白', 7.9874370130820465), ('美國加州北海岸紅', 7.000053631493185), ('法國波爾多聖朱里安紅', 5.999566331595941), ('法國布根地伯恩丘白', 5.999369191003067), ('法國布根地夜丘紅', 5.000510837584042), ('義大利托斯卡尼寶格麗紅', 4.017852162317627), ('法國波爾多聖愛美濃紅', 3.9992186739719218), ('法國香檳 白', 3.9989482611676523)]\n",
      "這是原本最高的前10個\n",
      "[('法國波爾多波雅克紅', 11.0), ('法國波爾多瑪歌紅', 8.0), ('法國香檳馬恩河谷白', 8.0), ('美國加州北海岸紅', 7.0), ('法國布根地伯恩丘白', 6.0), ('法國波爾多聖朱里安紅', 6.0), ('法國布根地夜丘紅', 5.0), ('法國波爾多貝沙克–雷奧良紅', 4.0), ('法國香檳 白', 4.0), ('義大利托斯卡尼寶格麗紅', 4.0)]\n",
      "\n",
      "\n",
      "723b7787cb8db4e2d5ff7dee3af65a49\n",
      "這是預測的最高前10個\n",
      "[('阿根廷門多薩 紅', 11.03166301182741), ('法國薄酒萊摩恭紅', 5.94837632762144), ('智利  紅', 4.054235454625705), ('澳洲南澳巴羅沙谷紅', 4.008851991432792), ('法國阿爾薩斯 白', 3.9862782135988906), ('阿根廷門多薩烏格河谷紅', 3.0650541840939125), ('法國布根地夏隆內丘白', 2.993109090847968), ('法國  紅', 2.826641172069695), ('法國薄酒萊風車磨坊紅', 2.6033507706394254), ('南非西開普區斯泰倫博斯紅', 2.5244379694356973)]\n",
      "這是原本最高的前10個\n",
      "[('阿根廷門多薩 紅', 11.0), ('法國薄酒萊摩恭紅', 6.0), ('法國阿爾薩斯 白', 4.0), ('南非西開普區斯泰倫博斯紅', 4.0), ('澳洲南澳巴羅沙谷紅', 4.0), ('智利  紅', 4.0), ('法國布根地夏隆內丘白', 3.0), ('法國  紅', 3.0), ('阿根廷門多薩烏格河谷紅', 3.0), ('法國薄酒萊風車磨坊紅', 3.0)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_results(predicted_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings_df.to_csv(\"/home/r12323007/work_icheers/2024june/LLORMA_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
